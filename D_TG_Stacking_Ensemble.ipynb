{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GUILLENJV/Optimizaci-n-de-Campa-as/blob/master/D_TG_Stacking_Ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f0912d0",
      "metadata": {
        "id": "7f0912d0"
      },
      "source": [
        "## Stacking Ensemble for Deep Learning Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66ee4f35",
      "metadata": {
        "id": "66ee4f35"
      },
      "source": [
        "### Nivel 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83bf15ac",
      "metadata": {
        "id": "83bf15ac"
      },
      "outputs": [],
      "source": [
        "#learned embedding encoding for a neural network\n",
        "from numpy import unique\n",
        "import numpy\n",
        "from numpy import array\n",
        "import pandas as pd\n",
        "import datetime\n",
        "from time import sleep\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from pandas import read_csv\n",
        "import json\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "#from keras.utils import np_utils\n",
        "from tensorflow.python.keras.utils import np_utils\n",
        "import requests\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.regularizers import l1\n",
        "from keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "#from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras import regularizers\n",
        "from matplotlib import pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "#from predict import model\n",
        "from sklearn import preprocessing\n",
        "from collections import defaultdict\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ca4815f",
      "metadata": {
        "id": "3ca4815f",
        "outputId": "c429591d-0709-47c4-9784-b59b941fa951",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: -c: line 1: syntax error near unexpected token `'models_1''\n",
            "/bin/bash: -c: line 1: `makedirs('models_1')'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "160/160 [==============================] - 3s 12ms/step - loss: 0.2575 - accuracy: 0.8968 - val_loss: 0.0851 - val_accuracy: 0.9632\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0812 - accuracy: 0.9626 - val_loss: 0.0694 - val_accuracy: 0.9684\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0726 - accuracy: 0.9656 - val_loss: 0.0654 - val_accuracy: 0.9703\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0691 - accuracy: 0.9673 - val_loss: 0.0640 - val_accuracy: 0.9705\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0668 - accuracy: 0.9675 - val_loss: 0.0634 - val_accuracy: 0.9719\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0650 - accuracy: 0.9688 - val_loss: 0.0632 - val_accuracy: 0.9728\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0634 - accuracy: 0.9694 - val_loss: 0.0632 - val_accuracy: 0.9728\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0620 - accuracy: 0.9705 - val_loss: 0.0634 - val_accuracy: 0.9732\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0607 - accuracy: 0.9714 - val_loss: 0.0636 - val_accuracy: 0.9737\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0594 - accuracy: 0.9722 - val_loss: 0.0640 - val_accuracy: 0.9739\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0582 - accuracy: 0.9731 - val_loss: 0.0644 - val_accuracy: 0.9742\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0571 - accuracy: 0.9742 - val_loss: 0.0649 - val_accuracy: 0.9739\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0560 - accuracy: 0.9742 - val_loss: 0.0653 - val_accuracy: 0.9742\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0550 - accuracy: 0.9745 - val_loss: 0.0659 - val_accuracy: 0.9735\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0539 - accuracy: 0.9751 - val_loss: 0.0665 - val_accuracy: 0.9742\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0530 - accuracy: 0.9762 - val_loss: 0.0670 - val_accuracy: 0.9737\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0520 - accuracy: 0.9769 - val_loss: 0.0677 - val_accuracy: 0.9737\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0512 - accuracy: 0.9776 - val_loss: 0.0684 - val_accuracy: 0.9732\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0502 - accuracy: 0.9779 - val_loss: 0.0688 - val_accuracy: 0.9728\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0493 - accuracy: 0.9782 - val_loss: 0.0694 - val_accuracy: 0.9730\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0485 - accuracy: 0.9783 - val_loss: 0.0697 - val_accuracy: 0.9730\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0476 - accuracy: 0.9787 - val_loss: 0.0703 - val_accuracy: 0.9730\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0468 - accuracy: 0.9794 - val_loss: 0.0707 - val_accuracy: 0.9728\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0459 - accuracy: 0.9799 - val_loss: 0.0710 - val_accuracy: 0.9728\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0451 - accuracy: 0.9799 - val_loss: 0.0712 - val_accuracy: 0.9728\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0443 - accuracy: 0.9805 - val_loss: 0.0714 - val_accuracy: 0.9730\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0435 - accuracy: 0.9807 - val_loss: 0.0719 - val_accuracy: 0.9732\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0428 - accuracy: 0.9811 - val_loss: 0.0720 - val_accuracy: 0.9735\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0420 - accuracy: 0.9813 - val_loss: 0.0725 - val_accuracy: 0.9737\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0413 - accuracy: 0.9816 - val_loss: 0.0727 - val_accuracy: 0.9737\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0406 - accuracy: 0.9820 - val_loss: 0.0731 - val_accuracy: 0.9737\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0399 - accuracy: 0.9822 - val_loss: 0.0734 - val_accuracy: 0.9732\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0392 - accuracy: 0.9825 - val_loss: 0.0738 - val_accuracy: 0.9730\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0385 - accuracy: 0.9827 - val_loss: 0.0742 - val_accuracy: 0.9732\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0378 - accuracy: 0.9832 - val_loss: 0.0744 - val_accuracy: 0.9732\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0371 - accuracy: 0.9839 - val_loss: 0.0749 - val_accuracy: 0.9732\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0365 - accuracy: 0.9837 - val_loss: 0.0751 - val_accuracy: 0.9735\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0358 - accuracy: 0.9848 - val_loss: 0.0758 - val_accuracy: 0.9737\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0351 - accuracy: 0.9851 - val_loss: 0.0762 - val_accuracy: 0.9739\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0345 - accuracy: 0.9859 - val_loss: 0.0766 - val_accuracy: 0.9737\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0337 - accuracy: 0.9869 - val_loss: 0.0770 - val_accuracy: 0.9737\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0331 - accuracy: 0.9871 - val_loss: 0.0773 - val_accuracy: 0.9737\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0324 - accuracy: 0.9877 - val_loss: 0.0781 - val_accuracy: 0.9737\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0318 - accuracy: 0.9881 - val_loss: 0.0788 - val_accuracy: 0.9737\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0312 - accuracy: 0.9882 - val_loss: 0.0792 - val_accuracy: 0.9737\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0305 - accuracy: 0.9884 - val_loss: 0.0801 - val_accuracy: 0.9737\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0300 - accuracy: 0.9884 - val_loss: 0.0806 - val_accuracy: 0.9737\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0294 - accuracy: 0.9889 - val_loss: 0.0813 - val_accuracy: 0.9735\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0287 - accuracy: 0.9893 - val_loss: 0.0820 - val_accuracy: 0.9737\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0282 - accuracy: 0.9893 - val_loss: 0.0827 - val_accuracy: 0.9735\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0276 - accuracy: 0.9895 - val_loss: 0.0834 - val_accuracy: 0.9735\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0270 - accuracy: 0.9896 - val_loss: 0.0839 - val_accuracy: 0.9728\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0264 - accuracy: 0.9898 - val_loss: 0.0850 - val_accuracy: 0.9728\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0259 - accuracy: 0.9899 - val_loss: 0.0856 - val_accuracy: 0.9726\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0254 - accuracy: 0.9903 - val_loss: 0.0860 - val_accuracy: 0.9726\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0248 - accuracy: 0.9906 - val_loss: 0.0868 - val_accuracy: 0.9721\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0243 - accuracy: 0.9907 - val_loss: 0.0872 - val_accuracy: 0.9721\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0238 - accuracy: 0.9906 - val_loss: 0.0885 - val_accuracy: 0.9719\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0233 - accuracy: 0.9915 - val_loss: 0.0888 - val_accuracy: 0.9716\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0229 - accuracy: 0.9914 - val_loss: 0.0898 - val_accuracy: 0.9712\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0224 - accuracy: 0.9917 - val_loss: 0.0904 - val_accuracy: 0.9712\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0220 - accuracy: 0.9920 - val_loss: 0.0913 - val_accuracy: 0.9710\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0216 - accuracy: 0.9922 - val_loss: 0.0919 - val_accuracy: 0.9712\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0211 - accuracy: 0.9922 - val_loss: 0.0929 - val_accuracy: 0.9710\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0207 - accuracy: 0.9923 - val_loss: 0.0935 - val_accuracy: 0.9705\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0203 - accuracy: 0.9924 - val_loss: 0.0943 - val_accuracy: 0.9705\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0199 - accuracy: 0.9924 - val_loss: 0.0951 - val_accuracy: 0.9707\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0196 - accuracy: 0.9923 - val_loss: 0.0961 - val_accuracy: 0.9705\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0193 - accuracy: 0.9924 - val_loss: 0.0969 - val_accuracy: 0.9705\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0189 - accuracy: 0.9925 - val_loss: 0.0973 - val_accuracy: 0.9705\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0187 - accuracy: 0.9925 - val_loss: 0.0982 - val_accuracy: 0.9703\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0183 - accuracy: 0.9929 - val_loss: 0.0993 - val_accuracy: 0.9700\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0181 - accuracy: 0.9928 - val_loss: 0.1000 - val_accuracy: 0.9700\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0178 - accuracy: 0.9932 - val_loss: 0.1007 - val_accuracy: 0.9700\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0175 - accuracy: 0.9930 - val_loss: 0.1015 - val_accuracy: 0.9700\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0173 - accuracy: 0.9934 - val_loss: 0.1023 - val_accuracy: 0.9700\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0171 - accuracy: 0.9935 - val_loss: 0.1026 - val_accuracy: 0.9698\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0168 - accuracy: 0.9932 - val_loss: 0.1040 - val_accuracy: 0.9696\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0166 - accuracy: 0.9932 - val_loss: 0.1039 - val_accuracy: 0.9698\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0164 - accuracy: 0.9933 - val_loss: 0.1052 - val_accuracy: 0.9696\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0162 - accuracy: 0.9933 - val_loss: 0.1055 - val_accuracy: 0.9698\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0160 - accuracy: 0.9934 - val_loss: 0.1065 - val_accuracy: 0.9696\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0158 - accuracy: 0.9932 - val_loss: 0.1071 - val_accuracy: 0.9696\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0157 - accuracy: 0.9930 - val_loss: 0.1074 - val_accuracy: 0.9694\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0154 - accuracy: 0.9932 - val_loss: 0.1080 - val_accuracy: 0.9691\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0153 - accuracy: 0.9931 - val_loss: 0.1085 - val_accuracy: 0.9691\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0151 - accuracy: 0.9931 - val_loss: 0.1088 - val_accuracy: 0.9694\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0150 - accuracy: 0.9929 - val_loss: 0.1087 - val_accuracy: 0.9689\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0148 - accuracy: 0.9932 - val_loss: 0.1096 - val_accuracy: 0.9689\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0147 - accuracy: 0.9932 - val_loss: 0.1099 - val_accuracy: 0.9687\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0145 - accuracy: 0.9933 - val_loss: 0.1099 - val_accuracy: 0.9687\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0144 - accuracy: 0.9935 - val_loss: 0.1109 - val_accuracy: 0.9680\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0142 - accuracy: 0.9935 - val_loss: 0.1106 - val_accuracy: 0.9680\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0141 - accuracy: 0.9935 - val_loss: 0.1110 - val_accuracy: 0.9680\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0140 - accuracy: 0.9935 - val_loss: 0.1111 - val_accuracy: 0.9680\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0138 - accuracy: 0.9933 - val_loss: 0.1124 - val_accuracy: 0.9673\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0137 - accuracy: 0.9935 - val_loss: 0.1118 - val_accuracy: 0.9677\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0136 - accuracy: 0.9934 - val_loss: 0.1124 - val_accuracy: 0.9671\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0134 - accuracy: 0.9938 - val_loss: 0.1123 - val_accuracy: 0.9668\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0135 - accuracy: 0.9937 - val_loss: 0.1125 - val_accuracy: 0.9671\n",
            ">Saved models_1/model_1.h5\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "160/160 [==============================] - 2s 9ms/step - loss: 0.2600 - accuracy: 0.8940 - val_loss: 0.0849 - val_accuracy: 0.9625\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0811 - accuracy: 0.9625 - val_loss: 0.0692 - val_accuracy: 0.9684\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0725 - accuracy: 0.9658 - val_loss: 0.0653 - val_accuracy: 0.9698\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0690 - accuracy: 0.9675 - val_loss: 0.0639 - val_accuracy: 0.9703\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0667 - accuracy: 0.9677 - val_loss: 0.0634 - val_accuracy: 0.9723\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0649 - accuracy: 0.9686 - val_loss: 0.0633 - val_accuracy: 0.9732\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0634 - accuracy: 0.9699 - val_loss: 0.0634 - val_accuracy: 0.9737\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0619 - accuracy: 0.9704 - val_loss: 0.0635 - val_accuracy: 0.9744\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0606 - accuracy: 0.9714 - val_loss: 0.0637 - val_accuracy: 0.9742\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0592 - accuracy: 0.9730 - val_loss: 0.0640 - val_accuracy: 0.9742\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0579 - accuracy: 0.9733 - val_loss: 0.0644 - val_accuracy: 0.9744\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0566 - accuracy: 0.9743 - val_loss: 0.0647 - val_accuracy: 0.9744\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0555 - accuracy: 0.9745 - val_loss: 0.0653 - val_accuracy: 0.9744\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0543 - accuracy: 0.9750 - val_loss: 0.0658 - val_accuracy: 0.9739\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0532 - accuracy: 0.9754 - val_loss: 0.0665 - val_accuracy: 0.9742\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0520 - accuracy: 0.9765 - val_loss: 0.0671 - val_accuracy: 0.9737\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0510 - accuracy: 0.9771 - val_loss: 0.0677 - val_accuracy: 0.9737\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0500 - accuracy: 0.9778 - val_loss: 0.0684 - val_accuracy: 0.9739\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0489 - accuracy: 0.9783 - val_loss: 0.0690 - val_accuracy: 0.9732\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0480 - accuracy: 0.9788 - val_loss: 0.0697 - val_accuracy: 0.9735\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0470 - accuracy: 0.9794 - val_loss: 0.0699 - val_accuracy: 0.9739\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0461 - accuracy: 0.9796 - val_loss: 0.0705 - val_accuracy: 0.9735\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0451 - accuracy: 0.9796 - val_loss: 0.0707 - val_accuracy: 0.9732\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0443 - accuracy: 0.9800 - val_loss: 0.0713 - val_accuracy: 0.9728\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0434 - accuracy: 0.9804 - val_loss: 0.0719 - val_accuracy: 0.9726\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0426 - accuracy: 0.9806 - val_loss: 0.0721 - val_accuracy: 0.9728\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0417 - accuracy: 0.9814 - val_loss: 0.0724 - val_accuracy: 0.9735\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0409 - accuracy: 0.9819 - val_loss: 0.0727 - val_accuracy: 0.9735\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0401 - accuracy: 0.9823 - val_loss: 0.0731 - val_accuracy: 0.9728\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0393 - accuracy: 0.9826 - val_loss: 0.0731 - val_accuracy: 0.9730\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0387 - accuracy: 0.9827 - val_loss: 0.0735 - val_accuracy: 0.9730\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0379 - accuracy: 0.9832 - val_loss: 0.0740 - val_accuracy: 0.9730\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0372 - accuracy: 0.9838 - val_loss: 0.0744 - val_accuracy: 0.9730\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0365 - accuracy: 0.9840 - val_loss: 0.0745 - val_accuracy: 0.9728\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0359 - accuracy: 0.9846 - val_loss: 0.0746 - val_accuracy: 0.9730\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0352 - accuracy: 0.9847 - val_loss: 0.0751 - val_accuracy: 0.9728\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0346 - accuracy: 0.9852 - val_loss: 0.0754 - val_accuracy: 0.9730\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0339 - accuracy: 0.9853 - val_loss: 0.0759 - val_accuracy: 0.9728\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0333 - accuracy: 0.9857 - val_loss: 0.0760 - val_accuracy: 0.9728\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0327 - accuracy: 0.9857 - val_loss: 0.0764 - val_accuracy: 0.9726\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0321 - accuracy: 0.9865 - val_loss: 0.0766 - val_accuracy: 0.9728\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0315 - accuracy: 0.9867 - val_loss: 0.0771 - val_accuracy: 0.9732\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0310 - accuracy: 0.9871 - val_loss: 0.0776 - val_accuracy: 0.9726\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0304 - accuracy: 0.9873 - val_loss: 0.0777 - val_accuracy: 0.9730\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0298 - accuracy: 0.9874 - val_loss: 0.0784 - val_accuracy: 0.9730\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0293 - accuracy: 0.9876 - val_loss: 0.0787 - val_accuracy: 0.9726\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0287 - accuracy: 0.9879 - val_loss: 0.0794 - val_accuracy: 0.9728\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0282 - accuracy: 0.9880 - val_loss: 0.0795 - val_accuracy: 0.9726\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0276 - accuracy: 0.9883 - val_loss: 0.0800 - val_accuracy: 0.9728\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0271 - accuracy: 0.9885 - val_loss: 0.0804 - val_accuracy: 0.9719\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0266 - accuracy: 0.9886 - val_loss: 0.0809 - val_accuracy: 0.9721\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0260 - accuracy: 0.9889 - val_loss: 0.0814 - val_accuracy: 0.9723\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0255 - accuracy: 0.9890 - val_loss: 0.0822 - val_accuracy: 0.9723\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0250 - accuracy: 0.9895 - val_loss: 0.0824 - val_accuracy: 0.9726\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0245 - accuracy: 0.9899 - val_loss: 0.0834 - val_accuracy: 0.9721\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0240 - accuracy: 0.9903 - val_loss: 0.0839 - val_accuracy: 0.9723\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0236 - accuracy: 0.9907 - val_loss: 0.0844 - val_accuracy: 0.9721\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0231 - accuracy: 0.9908 - val_loss: 0.0849 - val_accuracy: 0.9719\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0226 - accuracy: 0.9910 - val_loss: 0.0856 - val_accuracy: 0.9719\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0222 - accuracy: 0.9912 - val_loss: 0.0864 - val_accuracy: 0.9712\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0218 - accuracy: 0.9913 - val_loss: 0.0868 - val_accuracy: 0.9712\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0213 - accuracy: 0.9918 - val_loss: 0.0873 - val_accuracy: 0.9707\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0210 - accuracy: 0.9922 - val_loss: 0.0883 - val_accuracy: 0.9712\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0206 - accuracy: 0.9920 - val_loss: 0.0886 - val_accuracy: 0.9707\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0202 - accuracy: 0.9922 - val_loss: 0.0893 - val_accuracy: 0.9710\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0198 - accuracy: 0.9918 - val_loss: 0.0902 - val_accuracy: 0.9710\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0196 - accuracy: 0.9915 - val_loss: 0.0909 - val_accuracy: 0.9707\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0192 - accuracy: 0.9919 - val_loss: 0.0911 - val_accuracy: 0.9712\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0189 - accuracy: 0.9922 - val_loss: 0.0921 - val_accuracy: 0.9712\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0185 - accuracy: 0.9919 - val_loss: 0.0925 - val_accuracy: 0.9714\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0183 - accuracy: 0.9919 - val_loss: 0.0935 - val_accuracy: 0.9712\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0180 - accuracy: 0.9919 - val_loss: 0.0937 - val_accuracy: 0.9712\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0177 - accuracy: 0.9921 - val_loss: 0.0946 - val_accuracy: 0.9712\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0174 - accuracy: 0.9920 - val_loss: 0.0950 - val_accuracy: 0.9714\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0171 - accuracy: 0.9924 - val_loss: 0.0955 - val_accuracy: 0.9712\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0169 - accuracy: 0.9922 - val_loss: 0.0960 - val_accuracy: 0.9721\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0167 - accuracy: 0.9922 - val_loss: 0.0963 - val_accuracy: 0.9716\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0164 - accuracy: 0.9922 - val_loss: 0.0972 - val_accuracy: 0.9714\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0162 - accuracy: 0.9924 - val_loss: 0.0971 - val_accuracy: 0.9707\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0160 - accuracy: 0.9925 - val_loss: 0.0977 - val_accuracy: 0.9710\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0158 - accuracy: 0.9923 - val_loss: 0.0986 - val_accuracy: 0.9710\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0156 - accuracy: 0.9922 - val_loss: 0.0985 - val_accuracy: 0.9710\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0153 - accuracy: 0.9925 - val_loss: 0.0993 - val_accuracy: 0.9714\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0153 - accuracy: 0.9925 - val_loss: 0.0998 - val_accuracy: 0.9712\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0150 - accuracy: 0.9925 - val_loss: 0.1002 - val_accuracy: 0.9710\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0149 - accuracy: 0.9927 - val_loss: 0.1008 - val_accuracy: 0.9707\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0148 - accuracy: 0.9928 - val_loss: 0.1009 - val_accuracy: 0.9703\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0146 - accuracy: 0.9928 - val_loss: 0.1011 - val_accuracy: 0.9703\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0145 - accuracy: 0.9927 - val_loss: 0.1018 - val_accuracy: 0.9703\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0144 - accuracy: 0.9927 - val_loss: 0.1021 - val_accuracy: 0.9705\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0142 - accuracy: 0.9926 - val_loss: 0.1027 - val_accuracy: 0.9700\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0142 - accuracy: 0.9926 - val_loss: 0.1033 - val_accuracy: 0.9703\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0141 - accuracy: 0.9926 - val_loss: 0.1040 - val_accuracy: 0.9705\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0139 - accuracy: 0.9928 - val_loss: 0.1045 - val_accuracy: 0.9705\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0138 - accuracy: 0.9926 - val_loss: 0.1047 - val_accuracy: 0.9710\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0137 - accuracy: 0.9926 - val_loss: 0.1047 - val_accuracy: 0.9703\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0136 - accuracy: 0.9929 - val_loss: 0.1055 - val_accuracy: 0.9703\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0135 - accuracy: 0.9931 - val_loss: 0.1065 - val_accuracy: 0.9703\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0134 - accuracy: 0.9930 - val_loss: 0.1076 - val_accuracy: 0.9703\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0133 - accuracy: 0.9929 - val_loss: 0.1083 - val_accuracy: 0.9703\n",
            ">Saved models_1/model_2.h5\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.2592 - accuracy: 0.9004 - val_loss: 0.0851 - val_accuracy: 0.9643\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0810 - accuracy: 0.9627 - val_loss: 0.0690 - val_accuracy: 0.9684\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0720 - accuracy: 0.9665 - val_loss: 0.0650 - val_accuracy: 0.9700\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0682 - accuracy: 0.9676 - val_loss: 0.0637 - val_accuracy: 0.9716\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0656 - accuracy: 0.9683 - val_loss: 0.0632 - val_accuracy: 0.9730\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0636 - accuracy: 0.9697 - val_loss: 0.0631 - val_accuracy: 0.9735\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0617 - accuracy: 0.9708 - val_loss: 0.0632 - val_accuracy: 0.9737\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0601 - accuracy: 0.9719 - val_loss: 0.0635 - val_accuracy: 0.9744\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0585 - accuracy: 0.9727 - val_loss: 0.0638 - val_accuracy: 0.9746\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0571 - accuracy: 0.9738 - val_loss: 0.0642 - val_accuracy: 0.9746\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0558 - accuracy: 0.9745 - val_loss: 0.0645 - val_accuracy: 0.9744\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0544 - accuracy: 0.9753 - val_loss: 0.0651 - val_accuracy: 0.9737\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0532 - accuracy: 0.9759 - val_loss: 0.0656 - val_accuracy: 0.9735\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0521 - accuracy: 0.9763 - val_loss: 0.0662 - val_accuracy: 0.9730\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0510 - accuracy: 0.9767 - val_loss: 0.0669 - val_accuracy: 0.9735\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0500 - accuracy: 0.9771 - val_loss: 0.0673 - val_accuracy: 0.9732\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0490 - accuracy: 0.9777 - val_loss: 0.0676 - val_accuracy: 0.9732\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0480 - accuracy: 0.9778 - val_loss: 0.0681 - val_accuracy: 0.9735\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0471 - accuracy: 0.9781 - val_loss: 0.0684 - val_accuracy: 0.9730\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0461 - accuracy: 0.9786 - val_loss: 0.0688 - val_accuracy: 0.9732\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0453 - accuracy: 0.9793 - val_loss: 0.0688 - val_accuracy: 0.9730\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0444 - accuracy: 0.9797 - val_loss: 0.0693 - val_accuracy: 0.9732\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0436 - accuracy: 0.9803 - val_loss: 0.0696 - val_accuracy: 0.9732\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0428 - accuracy: 0.9807 - val_loss: 0.0698 - val_accuracy: 0.9732\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0420 - accuracy: 0.9809 - val_loss: 0.0698 - val_accuracy: 0.9730\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0413 - accuracy: 0.9814 - val_loss: 0.0699 - val_accuracy: 0.9735\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0405 - accuracy: 0.9817 - val_loss: 0.0703 - val_accuracy: 0.9730\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0399 - accuracy: 0.9819 - val_loss: 0.0705 - val_accuracy: 0.9732\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0391 - accuracy: 0.9826 - val_loss: 0.0705 - val_accuracy: 0.9735\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0384 - accuracy: 0.9828 - val_loss: 0.0708 - val_accuracy: 0.9732\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0377 - accuracy: 0.9830 - val_loss: 0.0709 - val_accuracy: 0.9739\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0371 - accuracy: 0.9832 - val_loss: 0.0713 - val_accuracy: 0.9737\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0364 - accuracy: 0.9838 - val_loss: 0.0713 - val_accuracy: 0.9737\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0357 - accuracy: 0.9848 - val_loss: 0.0716 - val_accuracy: 0.9739\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0350 - accuracy: 0.9852 - val_loss: 0.0720 - val_accuracy: 0.9739\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0345 - accuracy: 0.9855 - val_loss: 0.0724 - val_accuracy: 0.9739\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0337 - accuracy: 0.9860 - val_loss: 0.0724 - val_accuracy: 0.9742\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0331 - accuracy: 0.9862 - val_loss: 0.0728 - val_accuracy: 0.9739\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0326 - accuracy: 0.9865 - val_loss: 0.0735 - val_accuracy: 0.9737\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0319 - accuracy: 0.9869 - val_loss: 0.0739 - val_accuracy: 0.9737\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0314 - accuracy: 0.9873 - val_loss: 0.0742 - val_accuracy: 0.9739\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0308 - accuracy: 0.9876 - val_loss: 0.0748 - val_accuracy: 0.9739\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0302 - accuracy: 0.9879 - val_loss: 0.0752 - val_accuracy: 0.9739\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0296 - accuracy: 0.9879 - val_loss: 0.0756 - val_accuracy: 0.9739\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0291 - accuracy: 0.9883 - val_loss: 0.0760 - val_accuracy: 0.9737\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0285 - accuracy: 0.9884 - val_loss: 0.0765 - val_accuracy: 0.9737\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0280 - accuracy: 0.9887 - val_loss: 0.0772 - val_accuracy: 0.9735\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0275 - accuracy: 0.9893 - val_loss: 0.0776 - val_accuracy: 0.9735\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0270 - accuracy: 0.9892 - val_loss: 0.0780 - val_accuracy: 0.9735\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0264 - accuracy: 0.9894 - val_loss: 0.0786 - val_accuracy: 0.9737\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0259 - accuracy: 0.9899 - val_loss: 0.0795 - val_accuracy: 0.9737\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0255 - accuracy: 0.9898 - val_loss: 0.0797 - val_accuracy: 0.9737\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0251 - accuracy: 0.9905 - val_loss: 0.0802 - val_accuracy: 0.9737\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0246 - accuracy: 0.9905 - val_loss: 0.0807 - val_accuracy: 0.9737\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0241 - accuracy: 0.9910 - val_loss: 0.0818 - val_accuracy: 0.9732\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0237 - accuracy: 0.9913 - val_loss: 0.0822 - val_accuracy: 0.9730\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0233 - accuracy: 0.9913 - val_loss: 0.0833 - val_accuracy: 0.9726\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0230 - accuracy: 0.9914 - val_loss: 0.0839 - val_accuracy: 0.9726\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0225 - accuracy: 0.9917 - val_loss: 0.0845 - val_accuracy: 0.9726\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0221 - accuracy: 0.9921 - val_loss: 0.0854 - val_accuracy: 0.9726\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0217 - accuracy: 0.9918 - val_loss: 0.0854 - val_accuracy: 0.9719\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0213 - accuracy: 0.9919 - val_loss: 0.0865 - val_accuracy: 0.9714\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0210 - accuracy: 0.9919 - val_loss: 0.0867 - val_accuracy: 0.9714\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0206 - accuracy: 0.9923 - val_loss: 0.0881 - val_accuracy: 0.9714\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0203 - accuracy: 0.9923 - val_loss: 0.0894 - val_accuracy: 0.9710\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0199 - accuracy: 0.9921 - val_loss: 0.0896 - val_accuracy: 0.9710\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0196 - accuracy: 0.9921 - val_loss: 0.0905 - val_accuracy: 0.9707\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0193 - accuracy: 0.9922 - val_loss: 0.0911 - val_accuracy: 0.9712\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0190 - accuracy: 0.9921 - val_loss: 0.0923 - val_accuracy: 0.9712\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0187 - accuracy: 0.9921 - val_loss: 0.0927 - val_accuracy: 0.9712\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0184 - accuracy: 0.9918 - val_loss: 0.0931 - val_accuracy: 0.9712\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0183 - accuracy: 0.9918 - val_loss: 0.0944 - val_accuracy: 0.9714\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0179 - accuracy: 0.9920 - val_loss: 0.0949 - val_accuracy: 0.9714\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0177 - accuracy: 0.9922 - val_loss: 0.0954 - val_accuracy: 0.9714\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0174 - accuracy: 0.9920 - val_loss: 0.0964 - val_accuracy: 0.9714\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0173 - accuracy: 0.9922 - val_loss: 0.0972 - val_accuracy: 0.9714\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0170 - accuracy: 0.9923 - val_loss: 0.0976 - val_accuracy: 0.9712\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0168 - accuracy: 0.9926 - val_loss: 0.0983 - val_accuracy: 0.9714\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0166 - accuracy: 0.9925 - val_loss: 0.0986 - val_accuracy: 0.9714\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0164 - accuracy: 0.9923 - val_loss: 0.0997 - val_accuracy: 0.9712\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0162 - accuracy: 0.9925 - val_loss: 0.0995 - val_accuracy: 0.9712\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0160 - accuracy: 0.9925 - val_loss: 0.1005 - val_accuracy: 0.9714\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0159 - accuracy: 0.9927 - val_loss: 0.1010 - val_accuracy: 0.9712\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0157 - accuracy: 0.9930 - val_loss: 0.1012 - val_accuracy: 0.9714\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0155 - accuracy: 0.9930 - val_loss: 0.1019 - val_accuracy: 0.9703\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0153 - accuracy: 0.9932 - val_loss: 0.1024 - val_accuracy: 0.9703\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0152 - accuracy: 0.9933 - val_loss: 0.1027 - val_accuracy: 0.9703\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0151 - accuracy: 0.9933 - val_loss: 0.1033 - val_accuracy: 0.9696\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0148 - accuracy: 0.9931 - val_loss: 0.1033 - val_accuracy: 0.9694\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0147 - accuracy: 0.9932 - val_loss: 0.1036 - val_accuracy: 0.9694\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0147 - accuracy: 0.9932 - val_loss: 0.1042 - val_accuracy: 0.9684\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0145 - accuracy: 0.9932 - val_loss: 0.1049 - val_accuracy: 0.9680\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0144 - accuracy: 0.9932 - val_loss: 0.1051 - val_accuracy: 0.9680\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0143 - accuracy: 0.9931 - val_loss: 0.1055 - val_accuracy: 0.9675\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0143 - accuracy: 0.9931 - val_loss: 0.1056 - val_accuracy: 0.9673\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0141 - accuracy: 0.9930 - val_loss: 0.1060 - val_accuracy: 0.9671\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0140 - accuracy: 0.9933 - val_loss: 0.1065 - val_accuracy: 0.9673\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0139 - accuracy: 0.9932 - val_loss: 0.1065 - val_accuracy: 0.9671\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0138 - accuracy: 0.9933 - val_loss: 0.1076 - val_accuracy: 0.9671\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0136 - accuracy: 0.9934 - val_loss: 0.1076 - val_accuracy: 0.9673\n",
            ">Saved models_1/model_3.h5\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.2564 - accuracy: 0.8986 - val_loss: 0.0850 - val_accuracy: 0.9641\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0811 - accuracy: 0.9630 - val_loss: 0.0693 - val_accuracy: 0.9684\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0725 - accuracy: 0.9656 - val_loss: 0.0655 - val_accuracy: 0.9700\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0689 - accuracy: 0.9675 - val_loss: 0.0642 - val_accuracy: 0.9703\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0666 - accuracy: 0.9680 - val_loss: 0.0637 - val_accuracy: 0.9719\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0649 - accuracy: 0.9690 - val_loss: 0.0636 - val_accuracy: 0.9726\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0634 - accuracy: 0.9694 - val_loss: 0.0637 - val_accuracy: 0.9732\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0620 - accuracy: 0.9701 - val_loss: 0.0639 - val_accuracy: 0.9732\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0607 - accuracy: 0.9717 - val_loss: 0.0641 - val_accuracy: 0.9735\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0595 - accuracy: 0.9720 - val_loss: 0.0644 - val_accuracy: 0.9742\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0583 - accuracy: 0.9732 - val_loss: 0.0647 - val_accuracy: 0.9737\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0572 - accuracy: 0.9743 - val_loss: 0.0651 - val_accuracy: 0.9732\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0560 - accuracy: 0.9748 - val_loss: 0.0657 - val_accuracy: 0.9737\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0549 - accuracy: 0.9746 - val_loss: 0.0662 - val_accuracy: 0.9735\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0538 - accuracy: 0.9755 - val_loss: 0.0667 - val_accuracy: 0.9739\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0528 - accuracy: 0.9759 - val_loss: 0.0675 - val_accuracy: 0.9730\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0517 - accuracy: 0.9767 - val_loss: 0.0680 - val_accuracy: 0.9730\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0507 - accuracy: 0.9771 - val_loss: 0.0687 - val_accuracy: 0.9730\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0497 - accuracy: 0.9777 - val_loss: 0.0692 - val_accuracy: 0.9726\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0487 - accuracy: 0.9778 - val_loss: 0.0698 - val_accuracy: 0.9723\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0477 - accuracy: 0.9785 - val_loss: 0.0702 - val_accuracy: 0.9728\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0467 - accuracy: 0.9792 - val_loss: 0.0706 - val_accuracy: 0.9723\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0457 - accuracy: 0.9797 - val_loss: 0.0709 - val_accuracy: 0.9721\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0449 - accuracy: 0.9799 - val_loss: 0.0714 - val_accuracy: 0.9719\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0440 - accuracy: 0.9802 - val_loss: 0.0718 - val_accuracy: 0.9719\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0431 - accuracy: 0.9805 - val_loss: 0.0721 - val_accuracy: 0.9719\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0423 - accuracy: 0.9807 - val_loss: 0.0724 - val_accuracy: 0.9719\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0415 - accuracy: 0.9811 - val_loss: 0.0728 - val_accuracy: 0.9719\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0407 - accuracy: 0.9816 - val_loss: 0.0730 - val_accuracy: 0.9723\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0399 - accuracy: 0.9819 - val_loss: 0.0733 - val_accuracy: 0.9719\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0392 - accuracy: 0.9821 - val_loss: 0.0738 - val_accuracy: 0.9723\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0384 - accuracy: 0.9823 - val_loss: 0.0740 - val_accuracy: 0.9730\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0377 - accuracy: 0.9828 - val_loss: 0.0746 - val_accuracy: 0.9726\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0370 - accuracy: 0.9832 - val_loss: 0.0749 - val_accuracy: 0.9723\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0362 - accuracy: 0.9843 - val_loss: 0.0752 - val_accuracy: 0.9723\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0355 - accuracy: 0.9852 - val_loss: 0.0757 - val_accuracy: 0.9723\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0348 - accuracy: 0.9859 - val_loss: 0.0761 - val_accuracy: 0.9716\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0341 - accuracy: 0.9866 - val_loss: 0.0767 - val_accuracy: 0.9712\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0335 - accuracy: 0.9870 - val_loss: 0.0770 - val_accuracy: 0.9710\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0328 - accuracy: 0.9870 - val_loss: 0.0777 - val_accuracy: 0.9712\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0322 - accuracy: 0.9872 - val_loss: 0.0780 - val_accuracy: 0.9712\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0315 - accuracy: 0.9873 - val_loss: 0.0788 - val_accuracy: 0.9712\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0309 - accuracy: 0.9876 - val_loss: 0.0792 - val_accuracy: 0.9714\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0303 - accuracy: 0.9877 - val_loss: 0.0798 - val_accuracy: 0.9714\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0296 - accuracy: 0.9882 - val_loss: 0.0805 - val_accuracy: 0.9716\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0291 - accuracy: 0.9883 - val_loss: 0.0811 - val_accuracy: 0.9716\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0285 - accuracy: 0.9890 - val_loss: 0.0817 - val_accuracy: 0.9716\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0278 - accuracy: 0.9894 - val_loss: 0.0821 - val_accuracy: 0.9716\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0273 - accuracy: 0.9894 - val_loss: 0.0829 - val_accuracy: 0.9714\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0267 - accuracy: 0.9902 - val_loss: 0.0838 - val_accuracy: 0.9707\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0263 - accuracy: 0.9905 - val_loss: 0.0846 - val_accuracy: 0.9707\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0257 - accuracy: 0.9904 - val_loss: 0.0851 - val_accuracy: 0.9705\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0252 - accuracy: 0.9910 - val_loss: 0.0859 - val_accuracy: 0.9703\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0247 - accuracy: 0.9910 - val_loss: 0.0864 - val_accuracy: 0.9707\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0242 - accuracy: 0.9912 - val_loss: 0.0873 - val_accuracy: 0.9700\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0237 - accuracy: 0.9912 - val_loss: 0.0879 - val_accuracy: 0.9700\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0232 - accuracy: 0.9915 - val_loss: 0.0883 - val_accuracy: 0.9703\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0228 - accuracy: 0.9917 - val_loss: 0.0894 - val_accuracy: 0.9707\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0223 - accuracy: 0.9917 - val_loss: 0.0899 - val_accuracy: 0.9710\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0220 - accuracy: 0.9920 - val_loss: 0.0906 - val_accuracy: 0.9710\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0215 - accuracy: 0.9921 - val_loss: 0.0917 - val_accuracy: 0.9707\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0211 - accuracy: 0.9919 - val_loss: 0.0921 - val_accuracy: 0.9714\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0207 - accuracy: 0.9921 - val_loss: 0.0932 - val_accuracy: 0.9714\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0204 - accuracy: 0.9921 - val_loss: 0.0939 - val_accuracy: 0.9716\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0201 - accuracy: 0.9921 - val_loss: 0.0940 - val_accuracy: 0.9712\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0197 - accuracy: 0.9922 - val_loss: 0.0952 - val_accuracy: 0.9710\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0194 - accuracy: 0.9920 - val_loss: 0.0960 - val_accuracy: 0.9710\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0190 - accuracy: 0.9921 - val_loss: 0.0965 - val_accuracy: 0.9707\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0187 - accuracy: 0.9923 - val_loss: 0.0972 - val_accuracy: 0.9705\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0184 - accuracy: 0.9927 - val_loss: 0.0982 - val_accuracy: 0.9714\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0182 - accuracy: 0.9925 - val_loss: 0.0987 - val_accuracy: 0.9710\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0179 - accuracy: 0.9925 - val_loss: 0.0989 - val_accuracy: 0.9705\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0176 - accuracy: 0.9923 - val_loss: 0.1000 - val_accuracy: 0.9703\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0174 - accuracy: 0.9924 - val_loss: 0.0997 - val_accuracy: 0.9700\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0172 - accuracy: 0.9926 - val_loss: 0.1010 - val_accuracy: 0.9700\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0169 - accuracy: 0.9926 - val_loss: 0.1014 - val_accuracy: 0.9698\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0167 - accuracy: 0.9925 - val_loss: 0.1026 - val_accuracy: 0.9698\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0165 - accuracy: 0.9925 - val_loss: 0.1021 - val_accuracy: 0.9700\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0162 - accuracy: 0.9926 - val_loss: 0.1028 - val_accuracy: 0.9705\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0161 - accuracy: 0.9927 - val_loss: 0.1035 - val_accuracy: 0.9700\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0157 - accuracy: 0.9930 - val_loss: 0.1036 - val_accuracy: 0.9700\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0156 - accuracy: 0.9930 - val_loss: 0.1042 - val_accuracy: 0.9703\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0154 - accuracy: 0.9927 - val_loss: 0.1045 - val_accuracy: 0.9696\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0152 - accuracy: 0.9930 - val_loss: 0.1050 - val_accuracy: 0.9698\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0150 - accuracy: 0.9929 - val_loss: 0.1048 - val_accuracy: 0.9703\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0148 - accuracy: 0.9928 - val_loss: 0.1066 - val_accuracy: 0.9698\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0147 - accuracy: 0.9929 - val_loss: 0.1063 - val_accuracy: 0.9703\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 2s 9ms/step - loss: 0.0145 - accuracy: 0.9932 - val_loss: 0.1066 - val_accuracy: 0.9691\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0144 - accuracy: 0.9933 - val_loss: 0.1071 - val_accuracy: 0.9703\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0142 - accuracy: 0.9929 - val_loss: 0.1076 - val_accuracy: 0.9696\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0140 - accuracy: 0.9929 - val_loss: 0.1077 - val_accuracy: 0.9696\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0140 - accuracy: 0.9929 - val_loss: 0.1083 - val_accuracy: 0.9691\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0139 - accuracy: 0.9930 - val_loss: 0.1084 - val_accuracy: 0.9694\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0137 - accuracy: 0.9933 - val_loss: 0.1094 - val_accuracy: 0.9691\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0136 - accuracy: 0.9933 - val_loss: 0.1093 - val_accuracy: 0.9694\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0136 - accuracy: 0.9933 - val_loss: 0.1102 - val_accuracy: 0.9694\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0134 - accuracy: 0.9932 - val_loss: 0.1102 - val_accuracy: 0.9694\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0133 - accuracy: 0.9933 - val_loss: 0.1104 - val_accuracy: 0.9691\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0132 - accuracy: 0.9934 - val_loss: 0.1114 - val_accuracy: 0.9691\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0132 - accuracy: 0.9937 - val_loss: 0.1131 - val_accuracy: 0.9687\n",
            ">Saved models_1/model_4.h5\n",
            "Epoch 1/100\n",
            "160/160 [==============================] - 2s 8ms/step - loss: 0.2607 - accuracy: 0.8970 - val_loss: 0.0852 - val_accuracy: 0.9636\n",
            "Epoch 2/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0812 - accuracy: 0.9628 - val_loss: 0.0694 - val_accuracy: 0.9682\n",
            "Epoch 3/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0725 - accuracy: 0.9660 - val_loss: 0.0654 - val_accuracy: 0.9705\n",
            "Epoch 4/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0688 - accuracy: 0.9675 - val_loss: 0.0639 - val_accuracy: 0.9700\n",
            "Epoch 5/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0663 - accuracy: 0.9680 - val_loss: 0.0634 - val_accuracy: 0.9712\n",
            "Epoch 6/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0644 - accuracy: 0.9693 - val_loss: 0.0633 - val_accuracy: 0.9721\n",
            "Epoch 7/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0627 - accuracy: 0.9704 - val_loss: 0.0634 - val_accuracy: 0.9732\n",
            "Epoch 8/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0610 - accuracy: 0.9709 - val_loss: 0.0636 - val_accuracy: 0.9737\n",
            "Epoch 9/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0596 - accuracy: 0.9722 - val_loss: 0.0639 - val_accuracy: 0.9742\n",
            "Epoch 10/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0582 - accuracy: 0.9725 - val_loss: 0.0642 - val_accuracy: 0.9742\n",
            "Epoch 11/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0568 - accuracy: 0.9733 - val_loss: 0.0646 - val_accuracy: 0.9739\n",
            "Epoch 12/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0555 - accuracy: 0.9748 - val_loss: 0.0652 - val_accuracy: 0.9739\n",
            "Epoch 13/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0541 - accuracy: 0.9756 - val_loss: 0.0658 - val_accuracy: 0.9735\n",
            "Epoch 14/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0529 - accuracy: 0.9760 - val_loss: 0.0665 - val_accuracy: 0.9737\n",
            "Epoch 15/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0517 - accuracy: 0.9770 - val_loss: 0.0674 - val_accuracy: 0.9735\n",
            "Epoch 16/100\n",
            "160/160 [==============================] - 2s 12ms/step - loss: 0.0505 - accuracy: 0.9777 - val_loss: 0.0680 - val_accuracy: 0.9732\n",
            "Epoch 17/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0494 - accuracy: 0.9775 - val_loss: 0.0687 - val_accuracy: 0.9730\n",
            "Epoch 18/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0483 - accuracy: 0.9776 - val_loss: 0.0695 - val_accuracy: 0.9735\n",
            "Epoch 19/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0472 - accuracy: 0.9779 - val_loss: 0.0702 - val_accuracy: 0.9732\n",
            "Epoch 20/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0462 - accuracy: 0.9791 - val_loss: 0.0706 - val_accuracy: 0.9732\n",
            "Epoch 21/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0451 - accuracy: 0.9802 - val_loss: 0.0712 - val_accuracy: 0.9735\n",
            "Epoch 22/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0442 - accuracy: 0.9805 - val_loss: 0.0719 - val_accuracy: 0.9732\n",
            "Epoch 23/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0433 - accuracy: 0.9811 - val_loss: 0.0724 - val_accuracy: 0.9735\n",
            "Epoch 24/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0424 - accuracy: 0.9814 - val_loss: 0.0728 - val_accuracy: 0.9739\n",
            "Epoch 25/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0415 - accuracy: 0.9822 - val_loss: 0.0733 - val_accuracy: 0.9739\n",
            "Epoch 26/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0407 - accuracy: 0.9824 - val_loss: 0.0740 - val_accuracy: 0.9739\n",
            "Epoch 27/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0399 - accuracy: 0.9827 - val_loss: 0.0744 - val_accuracy: 0.9737\n",
            "Epoch 28/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0391 - accuracy: 0.9832 - val_loss: 0.0750 - val_accuracy: 0.9735\n",
            "Epoch 29/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0383 - accuracy: 0.9835 - val_loss: 0.0757 - val_accuracy: 0.9732\n",
            "Epoch 30/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0376 - accuracy: 0.9836 - val_loss: 0.0764 - val_accuracy: 0.9730\n",
            "Epoch 31/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0370 - accuracy: 0.9840 - val_loss: 0.0770 - val_accuracy: 0.9732\n",
            "Epoch 32/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0362 - accuracy: 0.9842 - val_loss: 0.0777 - val_accuracy: 0.9726\n",
            "Epoch 33/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0356 - accuracy: 0.9846 - val_loss: 0.0784 - val_accuracy: 0.9721\n",
            "Epoch 34/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0349 - accuracy: 0.9848 - val_loss: 0.0789 - val_accuracy: 0.9719\n",
            "Epoch 35/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0343 - accuracy: 0.9850 - val_loss: 0.0797 - val_accuracy: 0.9719\n",
            "Epoch 36/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0337 - accuracy: 0.9857 - val_loss: 0.0800 - val_accuracy: 0.9721\n",
            "Epoch 37/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0331 - accuracy: 0.9859 - val_loss: 0.0809 - val_accuracy: 0.9719\n",
            "Epoch 38/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0324 - accuracy: 0.9861 - val_loss: 0.0816 - val_accuracy: 0.9719\n",
            "Epoch 39/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0319 - accuracy: 0.9865 - val_loss: 0.0821 - val_accuracy: 0.9721\n",
            "Epoch 40/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0313 - accuracy: 0.9870 - val_loss: 0.0828 - val_accuracy: 0.9721\n",
            "Epoch 41/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0306 - accuracy: 0.9870 - val_loss: 0.0835 - val_accuracy: 0.9719\n",
            "Epoch 42/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0301 - accuracy: 0.9871 - val_loss: 0.0842 - val_accuracy: 0.9719\n",
            "Epoch 43/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0295 - accuracy: 0.9875 - val_loss: 0.0849 - val_accuracy: 0.9721\n",
            "Epoch 44/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0290 - accuracy: 0.9874 - val_loss: 0.0858 - val_accuracy: 0.9723\n",
            "Epoch 45/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0284 - accuracy: 0.9882 - val_loss: 0.0864 - val_accuracy: 0.9726\n",
            "Epoch 46/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0279 - accuracy: 0.9883 - val_loss: 0.0872 - val_accuracy: 0.9723\n",
            "Epoch 47/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0274 - accuracy: 0.9885 - val_loss: 0.0879 - val_accuracy: 0.9723\n",
            "Epoch 48/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0269 - accuracy: 0.9885 - val_loss: 0.0887 - val_accuracy: 0.9721\n",
            "Epoch 49/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0264 - accuracy: 0.9888 - val_loss: 0.0897 - val_accuracy: 0.9723\n",
            "Epoch 50/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0259 - accuracy: 0.9891 - val_loss: 0.0903 - val_accuracy: 0.9721\n",
            "Epoch 51/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0254 - accuracy: 0.9895 - val_loss: 0.0909 - val_accuracy: 0.9719\n",
            "Epoch 52/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0250 - accuracy: 0.9899 - val_loss: 0.0917 - val_accuracy: 0.9719\n",
            "Epoch 53/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0245 - accuracy: 0.9898 - val_loss: 0.0925 - val_accuracy: 0.9719\n",
            "Epoch 54/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0241 - accuracy: 0.9900 - val_loss: 0.0931 - val_accuracy: 0.9719\n",
            "Epoch 55/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0236 - accuracy: 0.9903 - val_loss: 0.0938 - val_accuracy: 0.9721\n",
            "Epoch 56/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0232 - accuracy: 0.9909 - val_loss: 0.0943 - val_accuracy: 0.9719\n",
            "Epoch 57/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0229 - accuracy: 0.9911 - val_loss: 0.0955 - val_accuracy: 0.9716\n",
            "Epoch 58/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0227 - accuracy: 0.9915 - val_loss: 0.0960 - val_accuracy: 0.9716\n",
            "Epoch 59/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0220 - accuracy: 0.9915 - val_loss: 0.0968 - val_accuracy: 0.9716\n",
            "Epoch 60/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0216 - accuracy: 0.9915 - val_loss: 0.0973 - val_accuracy: 0.9714\n",
            "Epoch 61/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0212 - accuracy: 0.9918 - val_loss: 0.0982 - val_accuracy: 0.9714\n",
            "Epoch 62/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0209 - accuracy: 0.9916 - val_loss: 0.0987 - val_accuracy: 0.9712\n",
            "Epoch 63/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0205 - accuracy: 0.9917 - val_loss: 0.0996 - val_accuracy: 0.9714\n",
            "Epoch 64/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0203 - accuracy: 0.9916 - val_loss: 0.1001 - val_accuracy: 0.9710\n",
            "Epoch 65/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0199 - accuracy: 0.9918 - val_loss: 0.1008 - val_accuracy: 0.9710\n",
            "Epoch 66/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0196 - accuracy: 0.9922 - val_loss: 0.1016 - val_accuracy: 0.9710\n",
            "Epoch 67/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0193 - accuracy: 0.9920 - val_loss: 0.1019 - val_accuracy: 0.9707\n",
            "Epoch 68/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0190 - accuracy: 0.9920 - val_loss: 0.1027 - val_accuracy: 0.9705\n",
            "Epoch 69/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0187 - accuracy: 0.9918 - val_loss: 0.1034 - val_accuracy: 0.9703\n",
            "Epoch 70/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0184 - accuracy: 0.9920 - val_loss: 0.1042 - val_accuracy: 0.9703\n",
            "Epoch 71/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0182 - accuracy: 0.9919 - val_loss: 0.1046 - val_accuracy: 0.9700\n",
            "Epoch 72/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0179 - accuracy: 0.9920 - val_loss: 0.1057 - val_accuracy: 0.9700\n",
            "Epoch 73/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0177 - accuracy: 0.9923 - val_loss: 0.1062 - val_accuracy: 0.9698\n",
            "Epoch 74/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0175 - accuracy: 0.9920 - val_loss: 0.1067 - val_accuracy: 0.9700\n",
            "Epoch 75/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0173 - accuracy: 0.9919 - val_loss: 0.1069 - val_accuracy: 0.9698\n",
            "Epoch 76/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0171 - accuracy: 0.9921 - val_loss: 0.1079 - val_accuracy: 0.9700\n",
            "Epoch 77/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0168 - accuracy: 0.9922 - val_loss: 0.1084 - val_accuracy: 0.9700\n",
            "Epoch 78/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0166 - accuracy: 0.9923 - val_loss: 0.1090 - val_accuracy: 0.9696\n",
            "Epoch 79/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0165 - accuracy: 0.9923 - val_loss: 0.1094 - val_accuracy: 0.9694\n",
            "Epoch 80/100\n",
            "160/160 [==============================] - 2s 11ms/step - loss: 0.0163 - accuracy: 0.9925 - val_loss: 0.1096 - val_accuracy: 0.9691\n",
            "Epoch 81/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0161 - accuracy: 0.9924 - val_loss: 0.1105 - val_accuracy: 0.9687\n",
            "Epoch 82/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0159 - accuracy: 0.9925 - val_loss: 0.1108 - val_accuracy: 0.9689\n",
            "Epoch 83/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0159 - accuracy: 0.9925 - val_loss: 0.1112 - val_accuracy: 0.9694\n",
            "Epoch 84/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0156 - accuracy: 0.9925 - val_loss: 0.1122 - val_accuracy: 0.9694\n",
            "Epoch 85/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0154 - accuracy: 0.9925 - val_loss: 0.1125 - val_accuracy: 0.9691\n",
            "Epoch 86/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0156 - accuracy: 0.9924 - val_loss: 0.1130 - val_accuracy: 0.9696\n",
            "Epoch 87/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0152 - accuracy: 0.9926 - val_loss: 0.1129 - val_accuracy: 0.9694\n",
            "Epoch 88/100\n",
            "160/160 [==============================] - 2s 10ms/step - loss: 0.0151 - accuracy: 0.9928 - val_loss: 0.1136 - val_accuracy: 0.9691\n",
            "Epoch 89/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0150 - accuracy: 0.9927 - val_loss: 0.1136 - val_accuracy: 0.9691\n",
            "Epoch 90/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0148 - accuracy: 0.9928 - val_loss: 0.1145 - val_accuracy: 0.9689\n",
            "Epoch 91/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0146 - accuracy: 0.9929 - val_loss: 0.1147 - val_accuracy: 0.9689\n",
            "Epoch 92/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0148 - accuracy: 0.9931 - val_loss: 0.1152 - val_accuracy: 0.9687\n",
            "Epoch 93/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0144 - accuracy: 0.9930 - val_loss: 0.1156 - val_accuracy: 0.9680\n",
            "Epoch 94/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0145 - accuracy: 0.9929 - val_loss: 0.1161 - val_accuracy: 0.9684\n",
            "Epoch 95/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0143 - accuracy: 0.9928 - val_loss: 0.1162 - val_accuracy: 0.9682\n",
            "Epoch 96/100\n",
            "160/160 [==============================] - 2s 13ms/step - loss: 0.0141 - accuracy: 0.9929 - val_loss: 0.1166 - val_accuracy: 0.9680\n",
            "Epoch 97/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0141 - accuracy: 0.9927 - val_loss: 0.1169 - val_accuracy: 0.9675\n",
            "Epoch 98/100\n",
            "160/160 [==============================] - 1s 8ms/step - loss: 0.0139 - accuracy: 0.9930 - val_loss: 0.1174 - val_accuracy: 0.9671\n",
            "Epoch 99/100\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0138 - accuracy: 0.9928 - val_loss: 0.1182 - val_accuracy: 0.9671\n",
            "Epoch 100/100\n",
            "160/160 [==============================] - 1s 9ms/step - loss: 0.0137 - accuracy: 0.9928 - val_loss: 0.1182 - val_accuracy: 0.9666\n",
            ">Saved models_1/model_5.h5\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"62f1ab79cc287b001f643389_clear_final.csv\")\n",
        "X = df[['campaign_id',\n",
        "        'traffic_source_id',\n",
        "        'visitor_device_browser',\n",
        "        'visitor_device_hardware_family',\n",
        "        'visitor_device_hardware_model',\n",
        "        'visitor_device_hardware_vendor',\n",
        "        'visitor_device_os_family',\n",
        "        'visitor_device_os_vendor',\n",
        "        'visitor_device_os_version',\n",
        "        'visitor_device_type',\n",
        "        'visitor_geo_location_cityName',\n",
        "        'visitor_geo_location_connection_typ',\n",
        "        'visitor_geo_location_countryCode',\n",
        "        'visitor_geo_location_isp',\n",
        "        'visitor_geo_location_regionName',\n",
        "        'visitor_tokens_adh',\n",
        "        'visitor_tokens_cadid',\n",
        "        'visitor_tokens_adi',\n",
        "        'converted_yes',\n",
        "        'converted_no']]\n",
        "y = df[[\"landing_page_id\"]]\n",
        "\n",
        "df = pd.concat([X, y], axis=1)\n",
        "\n",
        "# prepare input data\n",
        "def prepare_inputs(X_train, X_test):\n",
        "\toe = OneHotEncoder(handle_unknown='ignore')\n",
        "\toe.fit(X_train)\n",
        "\tX_train_enc = oe.transform(X_train)\n",
        "\tX_test_enc = oe.transform(X_test)\n",
        "\treturn X_train_enc, X_test_enc\n",
        "\n",
        "# prepare target\n",
        "def prepare_targets(y_train, y_test):\n",
        "  le = LabelEncoder()\n",
        "  le.fit(y_train)\n",
        "  y_train_enc = le.transform(y_train)\n",
        "  y_test_enc = le.transform(y_test)\n",
        "  y_train_enc = to_categorical(y_train_enc)\n",
        "  y_test_enc = to_categorical(y_test_enc)\n",
        "  return y_train_enc, y_test_enc\n",
        "\n",
        "# split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
        "\n",
        "# prepare input data\n",
        "X_train_enc, X_test_enc = prepare_inputs(X_train, X_test)\n",
        "\n",
        "# prepare output data\n",
        "y_train_enc, y_test_enc = prepare_targets(y_train, y_test)\n",
        "\n",
        "#y_train_ecn, y_test_enc = to_categorical(y_train_enc, y_test_enc)\n",
        "\n",
        "# define the  model\n",
        "\n",
        "\n",
        "# fit model on dataset\n",
        "def modelo_mlp(X_train_enc, y_train_enc):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(250, input_dim=X_train_enc.shape[1], activation='relu',\n",
        "                kernel_initializer='uniform'))\n",
        "  #model.add(Dropout(0.3))\n",
        "  #model.add(Dense(250, kernel_initializer = 'he_uniform',  activation = 'relu'))\n",
        "  #model.add(Dropout(0.3))\n",
        "  model.add(Dense(2, kernel_initializer = 'uniform', activation='sigmoid'))\n",
        "  # compile the keras model\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  # fit the keras model on the dataset\n",
        "  model.fit(X_train_enc, y_train_enc, epochs=100, batch_size=64, validation_data=(X_test_enc, y_test_enc), shuffle=False)\n",
        "  return model\n",
        "\n",
        "# create directory for models\n",
        "!makedirs('models_1')\n",
        "# fit and save models\n",
        "n_members = 5\n",
        "for i in range(n_members):\n",
        " # fit model\n",
        "  model = modelo_mlp(X_train_enc, y_train_enc)\n",
        " # save model\n",
        "  filename = 'models_1/model_' + str(i + 1) + '.h5'\n",
        "  model.save(filename)\n",
        "  print('>Saved %s' % filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d10ddd3",
      "metadata": {
        "id": "7d10ddd3"
      },
      "source": [
        "### Nivel 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d343cdb",
      "metadata": {
        "id": "3d343cdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7026697-9ac1-4671-d5f9-9cd622324b8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pydot) (3.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pydot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85c544e5",
      "metadata": {
        "id": "85c544e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6f705e2-4f94-4be6-f1fe-5e2f7794fc09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting concatenate\n",
            "  Downloading concatenate-0.1.2-py3-none-any.whl (2.8 kB)\n",
            "Collecting registrate<0.2.0,>=0.1.6 (from concatenate)\n",
            "  Downloading registrate-0.1.6-py3-none-any.whl (3.1 kB)\n",
            "Installing collected packages: registrate, concatenate\n",
            "Successfully installed concatenate-0.1.2 registrate-0.1.6\n"
          ]
        }
      ],
      "source": [
        "!pip install concatenate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a0e0b96",
      "metadata": {
        "id": "3a0e0b96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb20a640-7dbf-49f4-9068-886e638116a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">loaded models_1/model_1.h5\n",
            ">loaded models_1/model_2.h5\n",
            ">loaded models_1/model_3.h5\n",
            ">loaded models_1/model_4.h5\n",
            ">loaded models_1/model_5.h5\n",
            "Loaded 5 models\n",
            "Stacked Test Accuracy: 0.970\n"
          ]
        }
      ],
      "source": [
        "# stacked generalization with neural net meta model on blobs dataset\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import load_model\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "#from keras.layers.merge import concatenate\n",
        "#from keras.models import Concatenate\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from numpy import argmax\n",
        "\n",
        "\n",
        "# load models from file\n",
        "def load_all_models(n_models):\n",
        " all_models = list()\n",
        " for i in range(n_models):\n",
        " # define filename for this ensemble\n",
        "  filename = 'models_1/model_' + str(i + 1) + '.h5'\n",
        " # load model from file\n",
        "  model = load_model(filename)\n",
        " # add to list of members\n",
        "  all_models.append(model)\n",
        "  print('>loaded %s' % filename)\n",
        " return all_models\n",
        "\n",
        "\n",
        "# define stacked model from multiple member input models\n",
        "def define_stacked_model(members):\n",
        " # update all layers in all models to not be trainable\n",
        " for i in range(len(members)):\n",
        "  model = members[i]\n",
        "  for layer in model.layers:\n",
        " # make not trainable\n",
        "   layer.trainable = False\n",
        " # rename to avoid 'unique layer name' issue\n",
        "   layer._name = 'ensemble_' + str(i+1) + '_' + layer.name\n",
        " # define multi-headed input\n",
        "   ensemble_visible = [model.input for model in members]\n",
        " # concatenate merge output from each model\n",
        "   ensemble_outputs = [model.output for model in members]\n",
        "   merge = concatenate(ensemble_outputs)\n",
        "   hidden = Dense(10, activation='relu')(merge)\n",
        "   output = Dense(2, activation='sigmoid')(hidden)\n",
        "   model = Model(inputs=ensemble_visible, outputs=output)\n",
        " # plot graph of ensemble\n",
        "   plot_model(model, show_shapes=True, to_file='model_graph.png')\n",
        " # compile\n",
        "   model.compile(loss='binary_crossentropy', optimizer='adam',\n",
        "                 metrics=['accuracy'])\n",
        " return model\n",
        "\n",
        "# fit a stacked model\n",
        "def fit_stacked_model(model, inputX, inputy):\n",
        " # prepare input data\n",
        " X = [inputX for _ in range(len(model.input))]\n",
        " # encode output data\n",
        " #inputy_enc = to_categorical(inputy)\n",
        " # fit model\n",
        " model.fit(X, inputy, epochs=300, verbose=0)\n",
        "\n",
        "# make a prediction with a stacked model\n",
        "def predict_stacked_model(model, inputX):\n",
        " # prepare input data\n",
        " X = [inputX for _ in range(len(model.input))]\n",
        " # make prediction\n",
        " return model.predict(X, verbose=0)\n",
        "\n",
        "# load all models\n",
        "n_members = 5\n",
        "members = load_all_models(n_members)\n",
        "print('Loaded %d models' % len(members))\n",
        "# define ensemble model\n",
        "stacked_model = define_stacked_model(members)\n",
        "# fit stacked model on test dataset\n",
        "fit_stacked_model(stacked_model, X_test_enc, y_test_enc)\n",
        "# make predictions and evaluate\n",
        "yhat = predict_stacked_model(stacked_model, X_test_enc)\n",
        "yhat = np.argmax(yhat, axis=1)\n",
        "#yhat = to_categorical(yhat)\n",
        "y_test_enc = np.argmax(y_test_enc, axis=1)\n",
        "acc = accuracy_score(y_test_enc, yhat)\n",
        "print('Stacked Test Accuracy: %.3f' % acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "315281f8",
      "metadata": {
        "id": "315281f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "821138ed-5621-4823-f6c2-07a232d5dbf6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: title={'center': 'Matrix de confusión'}>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Se obtiene la matriz de confusión\n",
        "y_pred=predict_stacked_model(stacked_model, X_test_enc)\n",
        "y_pred=np.argmax(y_pred, axis=1)\n",
        "#y_test=np.argmax(y_test, axis=1)\n",
        "cm = confusion_matrix(y_test_enc, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "plt.title(\"Matrix de confusión\")\n",
        "sns.heatmap(cm,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=True, annot_kws={\"size\": 16})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ee7cfb1",
      "metadata": {
        "id": "7ee7cfb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a4b3cfe-d85f-4e68-d6fd-c1d870651a67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      2249\n",
            "           1       0.98      0.96      0.97      2123\n",
            "\n",
            "    accuracy                           0.97      4372\n",
            "   macro avg       0.97      0.97      0.97      4372\n",
            "weighted avg       0.97      0.97      0.97      4372\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Se obtiene las metricas de evaluación del modelo\n",
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(y_test_enc, y_pred)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_enc.shape"
      ],
      "metadata": {
        "id": "OIe3Y80hVbcU",
        "outputId": "fc5d60d5-ea9f-45dc-a345-2657a352e2a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "OIe3Y80hVbcU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4372,)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "conda_python3",
      "language": "python",
      "name": "conda_python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}